{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,Input\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "import imutils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed dataset\n",
    "df = pd.read_csv('./no_zebra_img11.csv')\n",
    "df['label'] = 'crosswalk'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the variables\n",
    "data=[]\n",
    "target=[]\n",
    "filename=[]\n",
    "images_folder_path=r\"./all_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#collecting the xmin,xmax,ymin,ymax values of the bounding boxes\n",
    "for index,rows in df.iterrows():\n",
    "    file,start_x,start_y,end_x,end_y,label=rows[\"imagePath\"],rows[\"xmin\"],rows[\"ymin\"],rows[\"xmax\"],rows[\"ymax\"],rows['label']\n",
    "    filename.append(file)\n",
    "    image_path=images_folder_path+file\n",
    "    image=cv2.imread(image_path)\n",
    "    h,w,_=image.shape\n",
    "    assert not isinstance(image,type(None)), 'image not found'\n",
    "   \n",
    "    start_x=start_x/w\n",
    "    start_y=start_y/h\n",
    "    end_x=end_x/w\n",
    "    end_y=end_y/h\n",
    "\n",
    "    #loading image, resizing and converting to array\n",
    "    image=load_img(image_path,target_size=(224,224))\n",
    "    image=img_to_array(image)\n",
    "    #data = all the images\n",
    "    data.append(image)\n",
    "    #target = all the labels (boundingboxes)\n",
    "    target.append((start_x,start_y,end_x,end_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to numpy array\n",
    "data=np.array(data,dtype=\"float32\")/255.0\n",
    "targets=np.array(target,dtype=\"float32\")\n",
    "\n",
    "#splitting the data into train and test\n",
    "train_images,validation_images,train_targets,validation_targets=train_test_split(data,targets,test_size=0.1,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating callbacks\n",
    "checkpoint_filepath = 'best_weights_balanced2.hdf5'\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='val_accuracy', patience=15, \n",
    "                        verbose=1, mode='max',restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                                      save_weights_only=False, \n",
    "                                      monitor='val_accuracy',\n",
    "                                      mode='max', \n",
    "                                      save_best_only=True)\n",
    "learningrate = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                          mode='max',\n",
    "                                          min_delta=0.03, patience=3, \n",
    "                                          factor=.5,\n",
    "                                          min_lr=0.00001, verbose=1)\n",
    "\n",
    "callbacks = [earlyStop, checkpoint, learningrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\",input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(512,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(Conv2D(512,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "opt=Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"mse\",optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use CUDA for GPU if available and train the model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "with tf.device('/cpu:0'):\n",
    "    model.fit(train_images,train_targets,validation_data=(validation_images,validation_targets),batch_size=16,epochs=8,callbacks=callbacks,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save('object_detect_balanced2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "model = load_model('best_weights_balanced.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model\n",
    "plt.figure(figsize=(12, 24))\n",
    "test_images_folder_path=\"/Users/Jorg/Data/crosswalk_data/test_images4/\"\n",
    "# adding images names in dataframe with category.\n",
    "test_image_path = os.listdir(test_images_folder_path)\n",
    "test_image_path = [test_images_folder_path + i for i in test_image_path]\n",
    "# print(test_image_path)\n",
    "for index,path in enumerate(test_image_path[0:18]):\n",
    "    test_image=load_img(path,target_size=(224,224))\n",
    "    test_image=np.array(test_image)/255\n",
    "    test_image=np.expand_dims(test_image,axis=0)\n",
    "# make bounding box predictions on the input image\n",
    "    prediction=model.predict(test_image)[0]\n",
    "    (startX,startY,endX,endY)=prediction\n",
    "\t# load the input image (in OpenCV format), resize it such that it\n",
    "\t# fits on our screen, and grab its dimensions\n",
    "    test_img=cv2.imread(path)\n",
    "    test_img=imutils.resize(test_img,width=600)\n",
    "    (h,w)=test_img.shape[:2]\n",
    "    # scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "    startX=int(startX*w)\n",
    "    startY=int(startY*h)\n",
    "    endX=int(endX*w)\n",
    "    endY=int(endY*h)\n",
    "    print(startX,startY,endX,endY)\n",
    "    # draw a bounding box surrounding the object so we can visualize it\n",
    "    if (endX-startX>40) and (endY-startY>40):\n",
    "        cv2.rectangle(test_img,(startX,startY),(endX,endY),(255,0,0),2)\n",
    "        plt.subplot(6, 3, index+1)\n",
    "        plt.imshow(test_img)\n",
    "        \n",
    "        #outputPath = '/Users/Jorg/Data/crosswalk_data/test_images/'\n",
    "        #outputPath = os.getcwd()\n",
    "        #outputFile = path[:-4]+'_detected.jpg'\n",
    "        #cv2.imwrite(os.path.join(outputPath , outputFile),test_img)\n",
    "    else:\n",
    "        cv2.rectangle(test_img,(0,0),(0,0),(255,0,0),2)\n",
    "        plt.subplot(6, 3, index+1)\n",
    "        plt.imshow(test_img)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"[INFO] cleaning up...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('cv_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "342e99b07707208f7fd5033d1baf4a5b4e141bab115fcab6bad6b532a7b83142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
